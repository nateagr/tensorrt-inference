{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:01.102742Z",
     "start_time": "2022-01-12T14:44:01.099657Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch_tensorrt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from removebg.basnet.model.u2net import U2NET\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U2NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:31.122607Z",
     "start_time": "2022-01-12T14:44:31.120374Z"
    }
   },
   "outputs": [],
   "source": [
    "img_paths = [\n",
    "    \"/home/g.racic/sync/cailimage/pix_images/images/526_95bd2ba559f6b06a26d34e6aa0730a12.jpg\",\n",
    "    \"/home/g.racic/sync/cailimage/pix_images/images/101_dd5783e2de4e0129850c5c347c00b6c4.jpg\",\n",
    "    \"/home/g.racic/sync/cailimage/pix_images/images/102_5673a8240902ac026c2b1faf553b4999.jpg\",\n",
    "    \"/home/g.racic/sync/cailimage/pix_images/images/103_85540ed2f1683e7a89cf5b729e7ae71b.jpg\",\n",
    "    \"/home/g.racic/sync/cailimage/pix_images/images/105_289028da5128a3e7c6882f37590978de.jpg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:33.155691Z",
     "start_time": "2022-01-12T14:44:33.152004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(352, 352), interpolation=bilinear, max_size=None, antialias=None)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts = transforms.Compose(\n",
    "    [transforms.Resize((352, 352)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((.485, .456, .406), (.229, .224, .225))]\n",
    ")\n",
    "fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:33.313877Z",
     "start_time": "2022-01-12T14:44:33.311387Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img_path: str):\n",
    "    image = Image.open(img_path)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    return fts(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:33.637937Z",
     "start_time": "2022-01-12T14:44:33.629305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 352, 352])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensors = [preprocess_img(img_path) for img_path in img_paths]\n",
    "img_tensors = torch.stack(img_tensors)\n",
    "img_tensors = img_tensors.to(\"cuda\")\n",
    "img_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:07.287599Z",
     "start_time": "2022-01-12T14:44:07.285564Z"
    }
   },
   "outputs": [],
   "source": [
    "# viewfs://preprod-am6/user/rat/imagelab/image_seg/removebg_u2net_352_v1.pth\n",
    "model_path = \"/home/g.racic/sync/removebg_u2net_352_v1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:07.928133Z",
     "start_time": "2022-01-12T14:44:07.675706Z"
    }
   },
   "outputs": [],
   "source": [
    "u2net = U2NET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:09.300460Z",
     "start_time": "2022-01-12T14:44:08.901955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u2net.load_state_dict(torch.load(model_path, map_location=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:10.320241Z",
     "start_time": "2022-01-12T14:44:10.247739Z"
    }
   },
   "outputs": [],
   "source": [
    "u2net = u2net.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:16:10.036073Z",
     "start_time": "2022-01-12T10:16:07.369769Z"
    }
   },
   "outputs": [],
   "source": [
    "traced_u2net = torch.jit.trace(u2net, [img_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:17:57.066072Z",
     "start_time": "2022-01-12T10:16:18.458461Z"
    }
   },
   "outputs": [],
   "source": [
    "# /!\\ BE CAREFUL HERE. WE NEED TO EITHER PROVIDE AN INPUT SPEC WITH SHAPE RANGE\n",
    "# OR THE INPUT USED FOR CALIBRATION MUST HAVE THE SAME SHAPE AS FOR INFERENCE\n",
    "trt_u2net = torch_tensorrt.compile(traced_u2net, \n",
    "    inputs= [img_tensors.half()],\n",
    "    enabled_precisions= { torch.half }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:17:57.073879Z",
     "start_time": "2022-01-12T10:17:57.068351Z"
    }
   },
   "outputs": [],
   "source": [
    "def benchmark(model, input_data, dtype='fp32', nwarmup=50, nruns=1000):\n",
    "    input_data = input_data.to(\"cuda\")\n",
    "    if dtype=='fp16':\n",
    "        input_data = input_data.half()\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            features = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%100==0:\n",
    "                print('Iteration %d/%d, ave batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())    \n",
    "    print('Average batch time: %.2f ms'%(np.mean(timings)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:17:57.085989Z",
     "start_time": "2022-01-12T10:17:57.075054Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = torch.rand((5, 3, 352, 352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:18:20.543783Z",
     "start_time": "2022-01-12T10:17:57.360545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 100/300, ave batch time 66.04 ms\n",
      "Iteration 200/300, ave batch time 66.15 ms\n",
      "Iteration 300/300, ave batch time 66.28 ms\n",
      "Input shape: torch.Size([5, 3, 352, 352])\n",
      "Average batch time: 66.28 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(u2net, input_data, nwarmup=50, nruns=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:18:44.155330Z",
     "start_time": "2022-01-12T10:18:20.545447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 100/300, ave batch time 67.45 ms\n",
      "Iteration 200/300, ave batch time 67.28 ms\n",
      "Iteration 300/300, ave batch time 66.99 ms\n",
      "Input shape: torch.Size([5, 3, 352, 352])\n",
      "Average batch time: 66.99 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(traced_u2net, input_data, nwarmup=50, nruns=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:18:53.193316Z",
     "start_time": "2022-01-12T10:18:44.157003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 100/300, ave batch time 25.73 ms\n",
      "Iteration 200/300, ave batch time 25.73 ms\n",
      "Iteration 300/300, ave batch time 25.72 ms\n",
      "Input shape: torch.Size([5, 3, 352, 352])\n",
      "Average batch time: 25.72 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_u2net, input_data, dtype=\"fp16\",nwarmup=50, nruns=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U2NETp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:18:53.198880Z",
     "start_time": "2022-01-12T10:18:53.194813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(192, 192), interpolation=bilinear, max_size=None, antialias=None)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts = transforms.Compose(\n",
    "    [transforms.Resize((192, 192)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((.485, .456, .406), (.229, .224, .225))]\n",
    ")\n",
    "fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:19:01.586151Z",
     "start_time": "2022-01-12T10:19:01.556506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 192, 192])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensors = [preprocess_img(img_path) for img_path in img_paths]\n",
    "img_tensors = torch.stack(img_tensors)\n",
    "img_tensors = img_tensors.to(\"cuda\")\n",
    "img_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:19:47.832038Z",
     "start_time": "2022-01-12T10:19:47.829842Z"
    }
   },
   "outputs": [],
   "source": [
    "# viewfs://preprod-am6/user/rat/imagelab/image_seg/removebg_u2netp_192_v1_standalone.pth\n",
    "model_path = \"/home/g.racic/sync/removebg_u2netp_192_v1_standalone.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:20:45.515002Z",
     "start_time": "2022-01-12T10:20:45.248363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Already torchscript model\n",
    "u2netp = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:21:02.547050Z",
     "start_time": "2022-01-12T10:21:02.533943Z"
    }
   },
   "outputs": [],
   "source": [
    "u2netp = u2netp.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:22:10.669214Z",
     "start_time": "2022-01-12T10:21:25.938149Z"
    }
   },
   "outputs": [],
   "source": [
    "# /!\\ BE CAREFUL HERE. WE NEED TO EITHER PROVIDE AN INPUT SPEC WITH SHAPE RANGE\n",
    "# OR THE INPUT USED FOR CALIBRATION MUST HAVE THE SAME SHAPE AS FOR INFERENCE\n",
    "trt_u2netp = torch_tensorrt.compile(u2netp, \n",
    "    inputs= [img_tensors.half()],\n",
    "    enabled_precisions= { torch.half }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:22:10.676070Z",
     "start_time": "2022-01-12T10:22:10.671134Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = torch.rand((5, 3, 192, 192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:22:15.860123Z",
     "start_time": "2022-01-12T10:22:10.677215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 100/300, ave batch time 13.75 ms\n",
      "Iteration 200/300, ave batch time 13.76 ms\n",
      "Iteration 300/300, ave batch time 13.76 ms\n",
      "Input shape: torch.Size([5, 3, 192, 192])\n",
      "Average batch time: 13.76 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(u2netp, input_data, nwarmup=50, nruns=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:22:25.230180Z",
     "start_time": "2022-01-12T10:22:22.347640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 100/300, ave batch time 8.17 ms\n",
      "Iteration 200/300, ave batch time 8.17 ms\n",
      "Iteration 300/300, ave batch time 8.17 ms\n",
      "Input shape: torch.Size([5, 3, 192, 192])\n",
      "Average batch time: 8.17 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_u2netp, input_data, dtype=\"fp16\",nwarmup=50, nruns=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tensorrt_env",
   "language": "python",
   "name": "tensorrt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}