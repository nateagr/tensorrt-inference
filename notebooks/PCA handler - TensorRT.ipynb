{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:30:21.505858Z",
     "start_time": "2022-01-14T15:30:19.947692Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers import XLMRobertaTokenizerFast\n",
    "from handlers.full.extra_files.model import ModelWithGlobalProjection, ModelOutputWithProjection, Model\n",
    "\n",
    "from tensorrt_inference.backend import load_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:30:25.235291Z",
     "start_time": "2022-01-14T15:30:21.507702Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:30:31.598423Z",
     "start_time": "2022-01-14T15:30:27.128080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelWithGlobalProjection(\n",
       "  (model): Model(\n",
       "    (base_model): XLMRobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (category_embeddings): Embedding(233, 768)\n",
       "  )\n",
       "  (projection): Linear(in_features=768, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/home/g.racic/sync/pca-targetting/model.pt\"\n",
    "model = ModelWithGlobalProjection(\n",
    "    model=Model(233), projection=torch.nn.Linear(768, 100, bias=False)\n",
    ")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:30:31.602601Z",
     "start_time": "2022-01-14T15:30:31.600022Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_model_output_with_projection(trt_outputs):\n",
    "    return ModelOutputWithProjection(\n",
    "        text_embedding=torch.Tensor(trt_outputs[0]), proj_text_embedding=torch.Tensor(trt_outputs[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:38:25.374880Z",
     "start_time": "2022-01-14T15:38:25.372435Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return tokenizer(\n",
    "            [text],\n",
    "            max_length=96,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:46:39.061357Z",
     "start_time": "2022-01-14T15:46:39.058989Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(inputs, model_fn):\n",
    "    with torch.no_grad():\n",
    "        return model_fn(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:30:38.271362Z",
     "start_time": "2022-01-14T15:30:38.232775Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_num_interop_threads(1)\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla pytorch on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:46:41.101197Z",
     "start_time": "2022-01-14T15:46:41.097871Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_fn(model, device):\n",
    "    def _inference_fn(inputs: Dict[str, torch.Tensor]):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        model_output = model(**inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        return model_output\n",
    "\n",
    "    return _inference_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:46:50.453989Z",
     "start_time": "2022-01-14T15:46:50.448769Z"
    }
   },
   "outputs": [],
   "source": [
    "def benchmark(model_fn, input_data, batch_size, nwarmup=50, nruns=1000):\n",
    "    _data = itertools.cycle(input_data)\n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for n in range(nwarmup):\n",
    "            inference(preprocess(next(_data)), model_fn)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            inference(preprocess(next(_data)), model_fn)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    " \n",
    "    print('Average throughput: %.2f example/second'%(batch_size/np.mean(timings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:38:07.472422Z",
     "start_time": "2022-01-14T15:38:07.466554Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tincidunt libero at urna accumsan, ut fermentum lacus placerat. Nulla elementum ut orci in tristique. Sed efficitur non sem ut vulputate. Duis risus eros, convallis sit amet maximus sed, molestie in lacus. In hac habitasse platea dictumst. Phasellus vel fermentum orci, nec porttitor ante. Proin malesuada odio a velit ultrices, at consectetur ante posuere.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "Aenean faucibus purus in velit malesuada convallis. Aliquam tristique, mi in hendrerit aliquam, diam nisi finibus dui, non faucibus ligula lacus eget magna. Sed laoreet ex ante, sit amet placerat risus blandit nec. Donec interdum arcu enim, quis elementum erat convallis in. Curabitur a interdum tortor. Praesent id consequat urna. Sed ornare pellentesque velit, in facilisis quam. Curabitur fringilla vitae quam in lacinia. Vivamus ut consequat leo. Nunc vulputate, lorem a ultrices egestas, eros mi accumsan felis, in sollicitudin mi turpis vel tellus. Cras tincidunt, lectus ac euismod eleifend, nunc ipsum gravida nisl, ac gravida lacus magna non dui. Pellentesque rhoncus ullamcorper convallis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:39:27.317214Z",
     "start_time": "2022-01-14T15:39:11.340710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/50, avg batch time 159.22 ms\n",
      "Iteration 20/50, avg batch time 159.28 ms\n",
      "Iteration 30/50, avg batch time 159.24 ms\n",
      "Iteration 40/50, avg batch time 159.35 ms\n",
      "Iteration 50/50, avg batch time 159.34 ms\n",
      "Average throughput: 6.28 example/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(inference_fn(model, \"cpu\"), text, 1, nwarmup=50, nruns=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Int8 XLM-Roberta-Base on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:39:52.090706Z",
     "start_time": "2022-01-14T15:39:50.918636Z"
    }
   },
   "outputs": [],
   "source": [
    "int8_cpu_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear, torch.nn.Embedding}, dtype=torch.qint8\n",
    ")\n",
    "int8_cpu_model = int8_cpu_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:40:12.840088Z",
     "start_time": "2022-01-14T15:40:03.319009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/50, avg batch time 95.84 ms\n",
      "Iteration 20/50, avg batch time 95.58 ms\n",
      "Iteration 30/50, avg batch time 95.45 ms\n",
      "Iteration 40/50, avg batch time 95.44 ms\n",
      "Iteration 50/50, avg batch time 95.32 ms\n",
      "Average throughput: 10.49 example/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(inference_fn(int8_cpu_model, \"cpu\"), text, 1, nwarmup=50, nruns=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla XLM-Robera-Base on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:40:27.040330Z",
     "start_time": "2022-01-14T15:40:26.719453Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:48:16.603835Z",
     "start_time": "2022-01-14T15:48:15.788606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/50, avg batch time 8.06 ms\n",
      "Iteration 20/50, avg batch time 8.06 ms\n",
      "Iteration 30/50, avg batch time 8.05 ms\n",
      "Iteration 40/50, avg batch time 8.04 ms\n",
      "Iteration 50/50, avg batch time 8.02 ms\n",
      "Average throughput: 124.64 example/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(inference_fn(model, \"cuda:0\"), text, 1, nwarmup=50, nruns=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fp16/Int8 TRT XLM-Roberta-Base on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:17:26.228497Z",
     "start_time": "2022-01-14T16:17:26.225393Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_fn_trt(model, device):\n",
    "    def _inference_fn(inputs: Dict[str, torch.Tensor]):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        model_output = model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        return model_output\n",
    "\n",
    "    return _inference_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:41:57.297958Z",
     "start_time": "2022-01-14T15:41:57.295748Z"
    }
   },
   "outputs": [],
   "source": [
    "trt_model_path = \"/home/g.racic/mode_trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:41:58.374095Z",
     "start_time": "2022-01-14T15:41:58.142040Z"
    }
   },
   "outputs": [],
   "source": [
    "trt_logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "runtime = trt.Runtime(trt_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:42:05.198510Z",
     "start_time": "2022-01-14T15:42:03.822659Z"
    }
   },
   "outputs": [],
   "source": [
    "trt_model = load_engine(\n",
    "    runtime=runtime, engine_file_path=trt_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:17:27.841742Z",
     "start_time": "2022-01-14T16:17:27.615923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/50, avg batch time 2.25 ms\n",
      "Iteration 20/50, avg batch time 2.21 ms\n",
      "Iteration 30/50, avg batch time 2.18 ms\n",
      "Iteration 40/50, avg batch time 2.17 ms\n",
      "Iteration 50/50, avg batch time 2.16 ms\n",
      "Average throughput: 462.62 example/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(inference_fn_trt(trt_model, \"cpu\"), text, 1, nwarmup=50, nruns=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tensorrt_env",
   "language": "python",
   "name": "tensorrt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}